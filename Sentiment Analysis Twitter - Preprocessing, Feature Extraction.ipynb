{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               timestamp                                               text\n",
      "NaN            Timestamp                                              Tweet\n",
      "0.0  2019-04-13 17:00:30  RT @TimeyinFreedom: This April, Night King vs ...\n",
      "1.0  2019-04-13 17:00:28     RT @abussey1: @BmorecraftbeerP Bring me Thanos\n",
      "2.0  2019-04-13 17:00:26  RT @uniquenawesome: Random characters that wou...\n",
      "3.0  2019-04-13 17:00:25  taylor swift works for marvel and is coming to...\n",
      "complete cleaning proccess.\n",
      "                                                text            timestamp\n",
      "0  rt april night king vs thanos conquer earth ba...  2019-04-13 17:00:30\n",
      "1                                    rt bring thanos  2019-04-13 17:00:28\n",
      "2           rt random characters would defeat thanos  2019-04-13 17:00:26\n",
      "3  taylor swift works marvel coming defeat thanos...  2019-04-13 17:00:25\n",
      "4  rt one pic describes every bad fortnite patch ...  2019-04-13 17:00:24\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 2 columns):\n",
      "text         1000 non-null object\n",
      "timestamp    1000 non-null object\n",
      "dtypes: object(2)\n",
      "memory usage: 15.7+ KB\n"
     ]
    }
   ],
   "source": [
    "#data cleaning\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "\n",
    "token = WordPunctTokenizer()\n",
    "regex1 = r'@[A-Za-z0-9/:]+'\n",
    "regex2 = r'https?://[A-Za-z0-9./]+'\n",
    "\n",
    "combined_pat = r'|'.join((regex1, regex2))\n",
    "stop_words = set(stopwords.words('english')) \n",
    "\n",
    "def tweet_cleaner(text):\n",
    "    soup = BeautifulSoup(text, 'lxml')\n",
    "    souped = soup.get_text()\n",
    "    stripped = re.sub(combined_pat, '', souped)\n",
    "    try:\n",
    "        clean = stripped.decode(\"utf-8\").replace(u\"\\ufffd\", \"?\")\n",
    "    except:\n",
    "        clean = stripped\n",
    "    letters_only = re.sub(\"[^a-zA-Z]\", \" \", clean)\n",
    "    lower_case = letters_only.lower()\n",
    "    words = token.tokenize(lower_case)\n",
    "    filtered_words = [w for w in words if not w in stop_words] \n",
    "    return (\" \".join(filtered_words)).strip()\n",
    "\n",
    "cols = ['timestamp','text']\n",
    "df_train = pd.read_csv(\"\\\\Users\\\\aftermath\\\\Documents\\\\Machine Learning\\\\Sentiment Analysis Tweet\\\\raw_data.csv\",header=None, names=cols)\n",
    "print(df_train.head())\n",
    "\n",
    "clean_tweet_texts = []\n",
    "for i in range(1000): #PLEASE DO PAY ATTENTION! 1000 -> INPUT FROM SCRAP DATA NOTEBOOK\n",
    "    clean_tweet_texts.append(tweet_cleaner(df_train['text'][i]))\n",
    "print(\"complete cleaning proccess.\")\n",
    "\n",
    "clean_df_train = pd.DataFrame(clean_tweet_texts,columns=['text'])\n",
    "clean_df_train['timestamp']=df_train.timestamp\n",
    "print(clean_df_train.head())\n",
    "\n",
    "clean_df_train.info()\n",
    "clean_df_train.to_csv(\"clean_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
